{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e09efd",
   "metadata": {},
   "source": [
    "\n",
    "# Multiclass Classification\n",
    "\n",
    "Building a neural network to solve a multiclass classification exercise using the PyTorch framework.<br>\n",
    "Classification is one of the basic machine learning exercises. A trained model aims to predict the class of an input unit with high accuracy. <br>\n",
    "This neural network uses supervised learning, meaning that the input datasets also provide target labels to train the model with. <br>\n",
    "<br>\n",
    "This Notebook has been generated automatically using the JupyterLab extension ***MLProvCodeGen***.\n",
    "<br>\n",
    "\n",
    "Original Source Code and inspiration from this article https://janakiev.com/blog/pytorch-iris/ <br>\n",
    "Original author: N. Janakiev https://github.com/njanakiev Twitter: https://twitter.com/njanakiev\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260d0dc",
   "metadata": {},
   "source": [
    "### Installs\n",
    "Install required packages before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b441949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy pandas matplotlib sklearn torch tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf58f50",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa73d90",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Ingestion\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "output_dim = len(names)\n",
    "feature_names = iris['feature_names']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b333ffe2",
   "metadata": {},
   "source": [
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preperation\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a77d5",
   "metadata": {},
   "source": [
    "### Data Segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Segregation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff39c25",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = X[y == target]\n",
    "    ax1.plot(X_plot[:, 0], X_plot[:, 1], \n",
    "             linestyle='none', \n",
    "             marker='o', \n",
    "             label=target_name)\n",
    "ax1.set_xlabel(feature_names[0])\n",
    "ax1.set_ylabel(feature_names[1])\n",
    "ax1.axis('equal')\n",
    "ax1.legend();\n",
    "\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = X[y == target]\n",
    "    ax2.plot(X_plot[:, 2], X_plot[:, 3], \n",
    "             linestyle='none', \n",
    "             marker='o', \n",
    "             label=target_name)\n",
    "ax2.set_xlabel(feature_names[2])\n",
    "ax2.set_ylabel(feature_names[3])\n",
    "ax2.axis('equal')\n",
    "ax2.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444419c9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use GPU?\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "#Configure Neural Network Models\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 50)\n",
    "        self.layer2 = nn.Linear(50, 50)\n",
    "        self.layer3 = nn.Linear(50, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model     = Model(X_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn   = nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fb8aa",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae638c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training\n",
    "EPOCHS  = 100\n",
    "X_train = Variable(torch.from_numpy(X_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()\n",
    "X_test  = Variable(torch.from_numpy(X_test)).float()\n",
    "y_test  = Variable(torch.from_numpy(y_test)).long()\n",
    "\n",
    "loss_list     = np.zeros((EPOCHS,))\n",
    "accuracy_list = np.zeros((EPOCHS,))\n",
    "\n",
    "for epoch in tqdm.trange(EPOCHS):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss_list[epoch] = loss.item()\n",
    "    \n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\n",
    "        accuracy_list[epoch] = correct.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00b04c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81317ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Accuracy and Loss from Training\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "\n",
    "ax1.plot(accuracy_list)\n",
    "ax1.set_ylabel(\"validation accuracy\")\n",
    "ax2.plot(loss_list)\n",
    "ax2.set_ylabel(\"validation loss\")\n",
    "ax2.set_xlabel(\"epochs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5d83f",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# One hot encoding\n",
    "enc = OneHotEncoder()\n",
    "Y_onehot = enc.fit_transform(y_test[:, np.newaxis]).toarray()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).numpy()\n",
    "    fpr, tpr, threshold = roc_curve(Y_onehot.ravel(), y_pred.ravel())\n",
    "    \n",
    "plt.plot(fpr, tpr, label='AUC = {:.3f}'.format(auc(fpr, tpr)))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
