{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1820ac08",
   "metadata": {},
   "source": [
    "\n",
    "# Multiclass Classification\n",
    "\n",
    "Building a neural network to solve a multiclass classification exercise using the PyTorch framework.<br>\n",
    "Classification is one of the basic machine learning exercises. A trained model aims to predict the class of an input unit with high accuracy. <br>\n",
    "This neural network uses supervised learning, meaning that the input datasets also provide target labels to train the model with. <br>\n",
    "<br>\n",
    "This Notebook has been generated automatically using the JupyterLab extension ***MLProvCodeGen***.\n",
    "<br>\n",
    "\n",
    "Original Source Code and inspiration from this article https://janakiev.com/blog/pytorch-iris/ <br>\n",
    "Original author: N. Janakiev https://github.com/njanakiev Twitter: https://twitter.com/njanakiev\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d803c2d",
   "metadata": {},
   "source": [
    "### Installs\n",
    "Install required packages before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efef6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy===1.22.2 pandas===1.3.3 matplotlib===3.5.1 sklearn==0.0 torch===1.8.0 tqdm===4.60.0 ipywidgets===7.6.5 pytorch-model-summary===0.1.2 ipython===7.31.1 gputil===1.4.0 psutil===5.9.0 py-cpuinfo===8.0.0 prov===2.0.0 pydot===1.4.2 --user\n",
    "#torch currently not supported with python 3.10, downgrading to python 3.9.7 possibly required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa137568",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8487cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import GPUtil\n",
    "import psutil\n",
    "import cpuinfo\n",
    "import platform\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, mean_absolute_error, mean_squared_error \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "import datetime\n",
    "from datetime import date\n",
    "from pytorch_model_summary import hierarchical_summary\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "import webbrowser\n",
    "import IPython\n",
    "from IPython.display import display, Image\n",
    "import prov\n",
    "from prov.model import ProvDocument, Namespace, Literal, PROV, Identifier\n",
    "from prov.dot import prov_to_dot\n",
    "import os\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b9b61d",
   "metadata": {},
   "source": [
    "### Provenance Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0bd194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(bytes, suffix=\"B\"):\n",
    "    \"\"\"\n",
    "    Scale bytes to its proper format\n",
    "    e.g:\n",
    "        1253656 => '1.20MB'\n",
    "        1253656678 => '1.17GB'\n",
    "    \"\"\"\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
    "        bytes /= factor\n",
    "\n",
    "d1 = ProvDocument()\n",
    "d1.add_namespace('prov', 'http://www.w3.org/ns/prov#')\n",
    "d1.add_namespace('ex', 'https://github.com/TarekAlMustafa/MLProvCodeGen1.0/')\n",
    "d1.add_namespace('foaf', 'http://xmlns.com/foaf/0.1/')\n",
    "d1.add_namespace('p-plan', 'http://purl.org/net/p-plan')\n",
    "\n",
    "e_MLProvCodeGen = d1.entity(\n",
    "        'ex:MLProvCodeGen',(\n",
    "            ('prov:type', PROV['Plan']),\n",
    "))\n",
    "ag_author = d1.agent(\n",
    "        'ex:Tarek Al Mustafa',(\n",
    "            ('prov:type', PROV['Person']),\n",
    "            ('foaf:givenName', 'Tarek Al Mustafa'),\n",
    "            ('foaf:mbox', '<tarek.almustafa@uni-jena.de>'),\n",
    "            ('prov:role', 'Author'),\n",
    "))\n",
    "kernellist = !jupyter kernelspec list\n",
    "e_notebook = d1.entity(\n",
    "        'ex:notebook',(\n",
    "            ('ex:programming_language','Python'),\n",
    "            ('ex:programming_language_version', cpuinfo.get_cpu_info()['python_version']),\n",
    "            ('ex:kernel','python3(ipykernel)'),\n",
    "            ('prov:type', PROV['File']),\n",
    "            ('ex:fileformat', '.ipynb'),\n",
    "            ('ex:name', 'MulticlassClassification.ipynb'),\n",
    "            ('ex:creation_date', str(date.today())),\n",
    "            ('ex:last_modified', 'TODO'),\n",
    "))\n",
    "e_notebook.add_asserted_type('prov:Collection')\n",
    "d1.wasAttributedTo(e_notebook, ag_author)\n",
    "a_generateNotebook = d1.activity('ex:GenerateNotebook')\n",
    "d1.wasAssociatedWith(a_generateNotebook, ag_author, plan=e_MLProvCodeGen)\n",
    "d1.wasGeneratedBy(e_notebook, a_generateNotebook)\n",
    "\n",
    "#set_experimentinfo\n",
    "e_experimentinfo = d1.entity('ex:Cell Experiment Info', (\n",
    "    ('ex:type', 'notebook_cell'),\n",
    "    ('ex:type', 'p-plan:step'),\n",
    "))\n",
    "a_setexperimentinfo = d1.activity('ex:set_experiment_info()')\n",
    "a_setdate = d1.activity('ex:date.today()')\n",
    "\n",
    "d1.wasStartedBy(a_setexperimentinfo,e_experimentinfo, time=datetime.datetime.now())\n",
    "d1.wasInformedBy(a_setexperimentinfo, a_setdate)  \n",
    "d1.hadMember(e_notebook, e_experimentinfo)\n",
    "e_experimentinfo_data = d1.entity(\n",
    "    'ex:Experiment Info Data',(\n",
    "        ('ex:title', 'Multiclass Classification'),\n",
    "        ('ex:creation_date', str(date.today())),\n",
    "        ('ex:task_type', 'MulticlassClassification'),\n",
    "))\n",
    "d1.wasGeneratedBy(e_experimentinfo_data, a_setexperimentinfo)\n",
    "\n",
    "#set_hardware_info()\n",
    "uname = platform.uname()\n",
    "sysInfo = str(uname.system +' '+ uname.release +' Version: '+ uname.version +' Machine: '+ uname.machine)\n",
    "    \n",
    "svmem = psutil.virtual_memory()\n",
    "\n",
    "GPUs = GPUtil.getGPUs()\n",
    "gpuList = []\n",
    "for gpu in GPUs:\n",
    "    gpu_id = gpu.id\n",
    "    gpu_name = gpu.name\n",
    "    gpuList.append((gpu_id , gpu_name))\n",
    "\n",
    "        \n",
    "e_hardwareinfo = d1.entity('ex:Cell Hardware Info', (\n",
    "    ('ex:type', 'notebook_cell'),\n",
    "    ('ex:type', 'p-plan:step'),\n",
    "))\n",
    "a_sethardwareinfo = d1.activity('ex:set_hardware_info()')\n",
    "a_platform_uname = d1.activity('ex:platform.uname()')\n",
    "a_cpuinfo = d1.activity('ex:cpuinfo.get_cpu_info()')\n",
    "a_svmemtotal = d1.activity('ex:svmem.total')\n",
    "a_getsize = d1.activity('ex:get_size(svmem.total)')\n",
    "a_GPUtilgetGPU = d1.activity('ex:GPUtil.getGPUs()')\n",
    "d1.wasStartedBy(a_sethardwareinfo, e_hardwareinfo, time=datetime.datetime.now())\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_platform_uname)\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_cpuinfo)\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_svmemtotal)\n",
    "d1.wasInformedBy(a_svmemtotal, a_getsize)\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_GPUtilgetGPU)\n",
    "d1.hadMember(e_notebook, e_hardwareinfo)\n",
    "e_hardwareinfo_data = d1.entity(\n",
    "    'ex:Hardware Info Data',(\n",
    "        ('ex:CPU', cpuinfo.get_cpu_info()['brand_raw']),\n",
    "        ('ex:RAM',  get_size(svmem.total)),\n",
    "        ('ex:Operating System', sysInfo),\n",
    "        ('ex:GPUs', str(gpuList)),\n",
    "))\n",
    "d1.wasGeneratedBy(e_hardwareinfo_data, a_sethardwareinfo)\n",
    "\n",
    "#set_packages\n",
    "cpuInfo_version = !pip list | grep -i py-cpuinfo\n",
    "pytorch_model_summary_version = !pip list | grep -i pytorch-model-summary\n",
    "\n",
    "\n",
    "e_packages = d1.entity('ex:Cell Packages', (\n",
    "    ('ex:type', 'notebook_cell'),\n",
    "    ('ex:type', 'p-plan:step'),\n",
    "))\n",
    "a_setpackages = d1.activity('ex:set_packages()', )\n",
    "a_getVersion = d1.activity('ex:{package_name}.__version__')\n",
    "a_getVersion_py_cpuinfo = d1.activity('ex:!pip list | grep -i py-cpuinfo')\n",
    "a_getVersion_pytorch_model_summary = d1.activity('ex:!pip list | grep -i pytorch-model-summary')\n",
    "d1.wasStartedBy(a_setpackages, e_packages, time=datetime.datetime.now())\n",
    "d1.wasInformedBy(a_setpackages,a_getVersion)\n",
    "d1.wasInformedBy(a_setpackages,a_getVersion_py_cpuinfo)\n",
    "d1.wasInformedBy(a_setpackages,a_getVersion_pytorch_model_summary)\n",
    "d1.hadMember(e_notebook, e_packages)\n",
    "\n",
    "e_packages_data = d1.entity(\n",
    "    'ex:Packages Data',(\n",
    "        ('ex:numpy', np.__version__),\n",
    "        ('ex:pandas', pd.__version__),\n",
    "        ('ex:matplotlib',  matplotlib.__version__),\n",
    "        ('ex:sklearn', sklearn.__version__),\n",
    "        ('ex:torch', torch.__version__),\n",
    "        ('ex:tqdm', tqdm.__version__),\n",
    "        ('ex:ipywidgets', widgets.__version__),\n",
    "        ('ex:pytorch-model-summary', pytorch_model_summary_version[0]),\n",
    "        ('ex:ipython', IPython.__version__),\n",
    "        ('ex:gputil', GPUtil.__version__),\n",
    "        ('ex:psutil', psutil.__version__),\n",
    "        ('ex:py-cpuinfo', cpuInfo_version[0]),\n",
    "        ('ex:prov', prov.__version__), \n",
    "))\n",
    "d1.wasGeneratedBy(e_packages_data, a_setpackages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1958289",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c79cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Ingestion\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "output_dim = len(names)\n",
    "feature_names = iris['feature_names']\n",
    "endtime = datetime.datetime.now()\n",
    "executionTime = endtime-starttime\n",
    "\n",
    "e_dataingestion = d1.entity('ex:Cell Data Ingestion', (\n",
    "    ('ex:type', 'notebook_cell'),\n",
    "    ('ex:type', 'p-plan:step'),\n",
    "))\n",
    "\n",
    "\n",
    "a_setdataingestion = d1.activity('ex:set_data_ingestion()', startTime=starttime, endTime=endtime, other_attributes={'prov:executionTime': str(executionTime)})\n",
    "d1.wasStartedBy(a_setdataingestion, e_dataingestion)\n",
    "d1.hadMember(e_notebook, e_dataingestion)\n",
    "e_dataingestion_data = d1.entity(\n",
    "    'ex:Data Ingestion Data',(\n",
    "        ('ex:dataset_id', 'Iris'),\n",
    "        ('ex:output_dimensions', output_dim),\n",
    "        ('ex:samples_total',  len(X)),\n",
    "        ('ex:feature_dimensions', len(feature_names)),\n",
    "))\n",
    "d1.wasGeneratedBy(e_dataingestion_data, a_setdataingestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a546f",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912cbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preperation\n",
    "starttime = datetime.datetime.now()\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "executionTime = endtime-starttime\n",
    "\n",
    "e_datapreparation = d1.entity('ex:Cell Data Preparation', (\n",
    "    ('ex:type', 'notebook_cell'),\n",
    "    ('ex:type', 'p-plan:step'),\n",
    "))\n",
    "a_setdatapreparation = d1.activity('ex:set_data_preparation()', startTime=starttime, endTime=endtime, other_attributes={'prov:executionTime': str(executionTime)})\n",
    "\n",
    "d1.wasStartedBy(a_setdatapreparation, e_datapreparation)\n",
    "d1.used(a_setdatapreparation, e_dataingestion_data)\n",
    "d1.hadMember(e_notebook, e_datapreparation)\n",
    "e_datapreparation_data = d1.entity(\n",
    "    'ex:Data Preparation Data',(\n",
    "        ('ex:number_operations', 1),\n",
    "        ('ex:transformation', 'sklearn.preprocessing.StandardScaler'),\n",
    "        ('ex:transformation_method', 'Standardscaler.fit_transform'),  \n",
    "))\n",
    "d1.wasGeneratedBy(e_datapreparation_data, a_setdatapreparation)\n",
    "d1.wasInfluencedBy(e_datapreparation, e_dataingestion_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee2183",
   "metadata": {},
   "source": [
    "### Data Segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb78ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Segregation\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "executionTime = endtime-starttime\n",
    "\n",
    "e_datasegregation = d1.entity('ex:Cell Data Segregation', (\n",
    "    ('ex:type', 'notebook_cell'),\n",
    "    ('ex:type', 'p-plan:step'),\n",
    "))\n",
    "a_setdatasegregation = d1.activity('ex:set_data_segregation()', startTime=starttime, endTime=endtime, other_attributes={'prov:executionTime': str(executionTime)})\n",
    "d1.wasStartedBy(a_setdatasegregation, e_datasegregation)\n",
    "d1.used(a_setdatasegregation, e_datapreparation_data)\n",
    "d1.hadMember(e_notebook, e_datasegregation)\n",
    "e_datasegregation_data = d1.entity(\n",
    "    'ex:Data Segregation Data',(\n",
    "        ('ex:segregation_method', 'sklearn.model_selection.train_test_split'),\n",
    "        ('ex:test_size', 0.2),\n",
    "        ('ex:train_size', 1-0.2), \n",
    "        ('ex:random_state', 2), \n",
    "))\n",
    "d1.wasGeneratedBy(e_datasegregation_data, a_setdatasegregation)\n",
    "d1.wasInfluencedBy(e_datasegregation, e_datapreparation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbfb133",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = X[y == target]\n",
    "    ax1.plot(X_plot[:, 0], X_plot[:, 1], \n",
    "             linestyle='none', \n",
    "             marker='o', \n",
    "             label=target_name)\n",
    "ax1.set_xlabel(feature_names[0])\n",
    "ax1.set_ylabel(feature_names[1])\n",
    "ax1.axis('equal')\n",
    "ax1.legend();\n",
    "\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = X[y == target]\n",
    "    ax2.plot(X_plot[:, 2], X_plot[:, 3], \n",
    "             linestyle='none', \n",
    "             marker='o', \n",
    "             label=target_name)\n",
    "ax2.set_xlabel(feature_names[2])\n",
    "ax2.set_ylabel(feature_names[3])\n",
    "ax2.axis('equal')\n",
    "ax2.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a9833",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a155d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "#Use GPU?\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "neuron_number = 50\n",
    "\n",
    "#Configure Neural Network Models\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 50)\n",
    "        self.layer2 = nn.Linear(50, 50)\n",
    "        self.layer3 = nn.Linear(50, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model     = Model(X_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn   = nn.CrossEntropyLoss()\n",
    "\n",
    "try:\n",
    "    lr\n",
    "except NameError:\n",
    "    default = 1\n",
    "    lr = None \n",
    "else:\n",
    "    default = 0\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "executionTime = endtime-starttime\n",
    "\n",
    "e_modelparameters = d1.entity('ex:Cell Model Parameters', (\n",
    "    ('ex:type', 'notebook_cell'),\n",
    "    ('ex:type', 'p-plan:step'),\n",
    "))\n",
    "a_setmodelparameters = d1.activity('ex:set_model_parameters()', startTime=starttime, endTime=endtime, other_attributes={'prov:executionTime': str(executionTime)})\n",
    "d1.wasStartedBy(a_setmodelparameters, e_modelparameters)\n",
    "d1.used(a_setmodelparameters, e_datasegregation_data)\n",
    "d1.hadMember(e_notebook, e_modelparameters)\n",
    "e_modelparameters_data = d1.entity(\n",
    "    'ex:Model Parameters Data',(\n",
    "        ('ex:gpu_enable', 1),\n",
    "        ('ex:modelParameters', 'str(model)TODO'),\n",
    "        ('ex:neuron_number', neuron_number), \n",
    "        ('ex:loss_function', 'nn.CrossEntropyLoss()'), \n",
    "        ('ex:optimizer', 'torch.optim.Adam('), \n",
    "        ('ex:optimizer_default_learning_rate', default), \n",
    "        ('ex:optimizer_learning_rate', str(lr)), \n",
    "        ('ex:activation_function', 'F.softmax(self.layer3(x), dim=1)'),  \n",
    "))\n",
    "d1.wasGeneratedBy(e_modelparameters_data, a_setmodelparameters)\n",
    "d1.wasInfluencedBy(e_modelparameters, e_datasegregation_data)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53f64a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "EPOCHS  = 100\n",
    "X_train = Variable(torch.from_numpy(X_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()\n",
    "X_test  = Variable(torch.from_numpy(X_test)).float()\n",
    "y_test  = Variable(torch.from_numpy(y_test)).long()\n",
    "\n",
    "loss_list     = np.zeros((EPOCHS,))\n",
    "accuracy_list = np.zeros((EPOCHS,))\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss_list[epoch] = loss.item()\n",
    "    \n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\n",
    "        accuracy_list[epoch] = correct.mean()\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "executionTime = endtime-starttime\n",
    "#set_training\n",
    "\n",
    "e_training = d1.entity('ex:Cell Training', (\n",
    "    ('ex:type', 'notebook_cell'),\n",
    "    ('ex:type', 'p-plan:step'),\n",
    "))\n",
    "a_settraining = d1.activity('ex:set_training()', startTime=starttime, endTime=endtime, other_attributes={'prov:executionTime': str(executionTime)})\n",
    "d1.wasStartedBy(a_settraining, e_training)\n",
    "d1.used(a_settraining, e_modelparameters_data)\n",
    "d1.hadMember(e_notebook, e_training)\n",
    "e_training_data = d1.entity(\n",
    "    'ex:Training Data',(\n",
    "        ('ex:epochs', EPOCHS),\n",
    "        ('ex:numberOfParameters', hierarchical_summary(model, print_summary = False)[1]),  \n",
    "))\n",
    "d1.wasGeneratedBy(e_training_data, a_settraining)\n",
    "d1.wasInfluencedBy(e_training, e_modelparameters_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ebd33",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "#Plot Accuracy and Loss from Training\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "\n",
    "ax1.plot(accuracy_list)\n",
    "ax1.set_ylabel(\"validation accuracy\")\n",
    "ax2.plot(loss_list)\n",
    "ax2.set_ylabel(\"validation loss\")\n",
    "ax2.set_xlabel(\"epochs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6434c",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix = confusion_matrix(y_test, torch.argmax(y_pred, dim=1))\n",
    "confusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1465a9",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f485e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = f1_score(y_test, torch.argmax(y_pred, dim=1), average=None)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e65e7",
   "metadata": {},
   "source": [
    "### Mean Absolute Error & Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(y_test, torch.argmax(y_pred, dim=1), multioutput='uniform_average')\n",
    "MSE = mean_squared_error(y_test, torch.argmax(y_pred, dim=1), multioutput='uniform_average')\n",
    "print(MAE)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac70d86",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ef7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# One hot encoding\n",
    "enc = OneHotEncoder()\n",
    "Y_onehot = enc.fit_transform(y_test[:, np.newaxis]).toarray()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).numpy()\n",
    "    fpr, tpr, threshold = roc_curve(Y_onehot.ravel(), y_pred.ravel())\n",
    "    \n",
    "plt.plot(fpr, tpr, label='AUC = {:.3f}'.format(auc(fpr, tpr)))\n",
    "AUC = '{:.5f}'.format(auc(fpr, tpr))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend();\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "executionTime = endtime-starttime\n",
    "#set_evaluation\n",
    "\n",
    "e_evaluation = d1.entity('ex:Cell Evaluation', (\n",
    "    ('ex:type', 'notebook_cell'),\n",
    "    ('ex:type', 'p-plan:step'),\n",
    "))\n",
    "a_setevaluation = d1.activity('ex:set_evaluation()', startTime=starttime, endTime=endtime, other_attributes={'prov:executionTime': str(executionTime)})\n",
    "d1.wasStartedBy(a_setevaluation, e_evaluation)\n",
    "d1.used(a_setevaluation, e_training_data)\n",
    "d1.hadMember(e_notebook, e_evaluation)\n",
    "e_evaluation_data = d1.entity(\n",
    "    'ex:Evaluation Data',(\n",
    "        ('ex:Accuracy', accuracy_list[(len(accuracy_list)-1)]),\n",
    "        ('ex:Loss', loss_list[(len(loss_list)-1)]),\n",
    "        ('ex:Confusion Matrix', str(confusionMatrix)),\n",
    "        ('ex:AUC', float(AUC)),\n",
    "        ('ex:F1 Score', str(F1)),\n",
    "        ('ex:Mean Absolute Error', MAE),\n",
    "        ('ex:Mean Squared Error', MSE), \n",
    "))\n",
    "d1.wasGeneratedBy(e_evaluation_data, a_setevaluation)\n",
    "d1.wasInfluencedBy(e_evaluation, e_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a338e",
   "metadata": {},
   "source": [
    "### Generate Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add visualization to PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "#get time for filenames\n",
    "timestring = datetime.datetime.now().strftime('%Y-%m-%d--%H-%M-%S')\n",
    "ProvenanceNameImage = ('Provenance_MulticlassClassification_' + timestring + '.png')\n",
    "\n",
    "dot = prov_to_dot(d1, direction='RL')\n",
    "dot.write_png('../GeneratedProvenanceData/'+ProvenanceNameImage)\n",
    "\n",
    "provenanceImage_open = widgets.Button(description = 'Open Image File')\n",
    "display(provenanceImage_open)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    provenanceImage_open.on_click = webbrowser.open('http://localhost:8888/lab/tree/GeneratedProvenanceData/'+ProvenanceNameImage)\n",
    "\n",
    "provenanceImage_open.on_click(on_button_clicked)\n",
    "Image('../GeneratedProvenanceData/'+ProvenanceNameImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ea8140",
   "metadata": {},
   "source": [
    "### Write Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProvenanceName = ('Provenance_MulticlassClassification_' + timestring + '.json')\n",
    "\n",
    "with open('../GeneratedProvenanceData/'+ProvenanceName, 'w') as prov_file:\n",
    "    prov_file.write(d1.serialize(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f0c82",
   "metadata": {},
   "source": [
    "### Show Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "provenance_open = widgets.Button(description = 'Open Provenance Data File')\n",
    "display(provenance_open)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    provenance_open.on_click = webbrowser.open('http://localhost:8888/lab/tree/extension/GeneratedProvenanceData/'+ProvenanceName)\n",
    "\n",
    "provenance_open.on_click(on_button_clicked)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
