{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0424a8d9",
   "metadata": {},
   "source": [
    "\n",
    "# Multiclass Classification\n",
    "\n",
    "Building a neural network to solve a multiclass classification exercise using the PyTorch framework.<br>\n",
    "Classification is one of the basic machine learning exercises. A trained model aims to predict the class of an input unit with high accuracy. <br>\n",
    "This neural network uses supervised learning, meaning that the input datasets also provide target labels to train the model with. <br>\n",
    "<br>\n",
    "This Notebook has been generated automatically using the JupyterLab extension ***MLProvCodeGen***.\n",
    "<br>\n",
    "\n",
    "Original Source Code and inspiration from this article https://janakiev.com/blog/pytorch-iris/ <br>\n",
    "Original author: N. Janakiev https://github.com/njanakiev Twitter: https://twitter.com/njanakiev\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43390d7",
   "metadata": {},
   "source": [
    "### Installs\n",
    "Install required packages before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408944b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy===1.22.2 pandas===1.3.3 matplotlib===3.5.1 sklearn==0.0 torch===1.8.0 tqdm===4.60.0 ipywidgets===7.6.5 pytorch-model-summary===0.1.2 ipython===7.31.1 gputil===1.4.0 psutil===5.9.0 py-cpuinfo===8.0.0 prov===2.0.0 pydot===1.4.2 --user\n",
    "#torch currently not supported with python 3.10, downgrading to python 3.9.7 possibly required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99473113",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import GPUtil\n",
    "import psutil\n",
    "import cpuinfo\n",
    "import platform\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, mean_absolute_error, mean_squared_error \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "from pytorch_model_summary import hierarchical_summary\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "import webbrowser\n",
    "import IPython\n",
    "from IPython.display import display, Image\n",
    "import prov\n",
    "from prov.model import ProvDocument\n",
    "from prov.dot import prov_to_dot\n",
    "import os\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16afd9f7",
   "metadata": {},
   "source": [
    "### Provenance Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193489b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(bytes, suffix=\"B\"):\n",
    "    \"\"\"\n",
    "    Scale bytes to its proper format\n",
    "    e.g:\n",
    "        1253656 => '1.20MB'\n",
    "        1253656678 => '1.17GB'\n",
    "    \"\"\"\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
    "        bytes /= factor\n",
    "\n",
    "d1 = ProvDocument()\n",
    "d1.set_default_namespace('provenanceexample.org')\n",
    "#set_experiment_info()\n",
    "d1.add_namespace('experimentinfo', 'experimentinfo.org')\n",
    "e_experimentinfo = d1.entity('experiment_info', (\n",
    "    ('experimentinfo:author', 'Tarek Al Mustafa'),\n",
    "    ('experimentinfo:email', 'tarek.almustafa@uni-jena.de'),\n",
    "    ('experimentinfo:title', 'Multiclass Classification'),\n",
    "    ('experimentinfo:creation_date', str(date.today())),\n",
    "    ('experimentinfo:task_type', 'MulticlassClassification'),\n",
    "))\n",
    "\n",
    "a_setexperimentinfo = d1.activity('set_experiment_info()', datetime.datetime.now(), None)\n",
    "a_setdate = d1.activity('date.today()')\n",
    "\n",
    "d1.wasGeneratedBy(e_experimentinfo, a_setexperimentinfo, None, {'ex:fct': 'set'})\n",
    "d1.wasAssociatedWith('experiment_info', 'Tarek Al Mustafa', None, None)\n",
    "d1.agent('Tarek Al Mustafa') \n",
    "d1.wasInformedBy(a_setexperimentinfo, a_setdate)   \n",
    "\n",
    "\n",
    "#set_hardware_info()\n",
    "uname = platform.uname()\n",
    "sysInfo = str(uname.system +' '+ uname.release +' Version: '+ uname.version +' Machine: '+ uname.machine)\n",
    "    \n",
    "svmem = psutil.virtual_memory()\n",
    "\n",
    "GPUs = GPUtil.getGPUs()\n",
    "gpuList = []\n",
    "for gpu in GPUs:\n",
    "    gpu_id = gpu.id\n",
    "    gpu_name = gpu.name\n",
    "    gpuList.append((gpu_id , gpu_name))\n",
    "\n",
    "        \n",
    "d1.add_namespace('hardwareinfo', 'hardwareinfo.org')\n",
    "e_hardwareinfo = d1.entity('hardware_info', (\n",
    "    ('hardwareinfo:Python Version', cpuinfo.get_cpu_info()['python_version']),\n",
    "    ('hardwareinfo:CPU', cpuinfo.get_cpu_info()['brand_raw']),\n",
    "    ('hardwareinfo:RAM',  get_size(svmem.total)),\n",
    "    ('hardwareinfo:Operating System', sysInfo),\n",
    "    ('hardwareinfo:GPUs', str(gpuList)),\n",
    "))\n",
    "#activity\n",
    "a_sethardwareinfo = d1.activity('set_hardware_info()', datetime.datetime.now(), None)\n",
    "a_platform_uname = d1.activity('platform.uname()')\n",
    "a_cpuinfo = d1.activity('cpuinfo.get_cpu_info()')\n",
    "a_svmemtotal = d1.activity('svmem.total')\n",
    "a_getsize = d1.activity('get_size(svmem.total)')\n",
    "a_GPUtilgetGPU = d1.activity('GPUtil.getGPUs()')\n",
    "d1.wasGeneratedBy(e_hardwareinfo, a_sethardwareinfo, None, {'experimentinfo:fct': 'set'})\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_platform_uname)\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_cpuinfo)\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_svmemtotal)\n",
    "d1.wasInformedBy(a_svmemtotal, a_getsize)\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_GPUtilgetGPU)\n",
    "\n",
    "\n",
    "#set_packages\n",
    "cpuInfo_version = !pip list | grep -i py-cpuinfo\n",
    "pytorch_model_summary_version = !pip list | grep -i pytorch-model-summary\n",
    "\n",
    "d1.add_namespace('packages', 'packages.org')\n",
    "\n",
    "e_packages = d1.entity('packages', (\n",
    "    ('packages:numpy', np.__version__),\n",
    "    ('packages:pandas', pd.__version__),\n",
    "    ('packages:matplotlib',  matplotlib.__version__),\n",
    "    ('packages:sklearn', sklearn.__version__),\n",
    "    ('packages:torch', torch.__version__),\n",
    "    ('packages:tqdm', tqdm.__version__),\n",
    "    ('packages:ipywidgets', widgets.__version__),\n",
    "    ('packages:pytorch-model-summary', pytorch_model_summary_version[0]),\n",
    "    ('packages:ipython', IPython.__version__),\n",
    "    ('packages:gputil', GPUtil.__version__),\n",
    "    ('packages:psutil', psutil.__version__),\n",
    "    ('packages:py-cpuinfo', cpuInfo_version[0]),\n",
    "    ('packages:prov', prov.__version__),  \n",
    "))\n",
    "a_setpackages = d1.activity('set_packages()', datetime.datetime.now())\n",
    "a_getVersion = d1.activity('{package_name}.__version__')\n",
    "a_getVersion_py_cpuinfo = d1.activity('!pip list | grep -i py-cpuinfo')\n",
    "a_getVersion_pytorch_model_summary = d1.activity('!pip list | grep -i pytorch-model-summary')\n",
    "d1.wasGeneratedBy(e_packages, a_setpackages, None, {'packages:fct': 'set'})\n",
    "d1.wasInformedBy(a_setpackages,a_getVersion)\n",
    "d1.wasInformedBy(a_setpackages,a_getVersion_py_cpuinfo)\n",
    "d1.wasInformedBy(a_setpackages,a_getVersion_pytorch_model_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203f79f",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Ingestion\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "output_dim = len(names)\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "#set_data_ingestion\n",
    "d1.add_namespace('dataingestion', 'dataingestion.org')\n",
    "\n",
    "e_dataingestion = d1.entity('data_ingestion', (\n",
    "    ('dataingestion:dataset_id', 'Iris'),\n",
    "    ('dataingestion:output_dimensions', output_dim),\n",
    "    ('dataingestion:samples_total',  len(X)),\n",
    "    ('dataingestion:feature_dimensions', len(feature_names)),  \n",
    "))\n",
    "a_setdataingestion = d1.activity('set_data_ingestion()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_dataingestion, a_setdataingestion, None, {'packages:fct': 'set'})\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a96252",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c71cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preperation\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#set_data_preparation\n",
    "d1.add_namespace('datapreparation', 'datapreparation.org')\n",
    "\n",
    "e_datapreparation = d1.entity('data_preparation', (\n",
    "    ('datapreparation:number_operations', 1),\n",
    "    ('datapreparation:transformation', 'sklearn.preprocessing.StandardScaler'),\n",
    "    ('datapreparation:transformation_method', 'Standardscaler.fit_transform'), \n",
    "))\n",
    "a_setdatapreparation = d1.activity('set_data_preparation()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_datapreparation, a_setdatapreparation, None, {'packages:fct': 'set'})\n",
    "d1.used(a_setdatapreparation, e_dataingestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6788f",
   "metadata": {},
   "source": [
    "### Data Segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Segregation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)\n",
    "\t\n",
    "#set_data_segregation\n",
    "d1.add_namespace('datasegregation', 'datasegregation.org')\n",
    "\n",
    "e_datasegregation = d1.entity('data_segregation', (\n",
    "    ('datasegregation:segregation_method', 'sklearn.model_selection.train_test_split'),\n",
    "    ('datasegregation:test_size', 0.2),\n",
    "    ('datasegregation:train_size', 1-0.2), \n",
    "    ('datasegregation:random_state', 2), \n",
    "))\n",
    "a_setdatasegregation = d1.activity('set_data_segregation()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_datasegregation, a_setdatasegregation, None, {'packages:fct': 'set'})\n",
    "d1.used(a_setdatasegregation, e_datapreparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226e56c",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = X[y == target]\n",
    "    ax1.plot(X_plot[:, 0], X_plot[:, 1], \n",
    "             linestyle='none', \n",
    "             marker='o', \n",
    "             label=target_name)\n",
    "ax1.set_xlabel(feature_names[0])\n",
    "ax1.set_ylabel(feature_names[1])\n",
    "ax1.axis('equal')\n",
    "ax1.legend();\n",
    "\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = X[y == target]\n",
    "    ax2.plot(X_plot[:, 2], X_plot[:, 3], \n",
    "             linestyle='none', \n",
    "             marker='o', \n",
    "             label=target_name)\n",
    "ax2.set_xlabel(feature_names[2])\n",
    "ax2.set_ylabel(feature_names[3])\n",
    "ax2.axis('equal')\n",
    "ax2.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a0e93",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use GPU?\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "neuron_number = 50\n",
    "\n",
    "#Configure Neural Network Models\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 50)\n",
    "        self.layer2 = nn.Linear(50, 50)\n",
    "        self.layer3 = nn.Linear(50, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model     = Model(X_train.shape[1])\n",
    "lr=0 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) loss_fn   = nn.CrossEntropyLoss()\n",
    "\n",
    "try:\n",
    "    lr\n",
    "except NameError:\n",
    "    default = 1\n",
    "    lr = None \n",
    "else:\n",
    "    default = 0\n",
    "\n",
    "#set_model_parameters\n",
    "d1.add_namespace('modelparameters', 'modelparameters.org')\n",
    "\n",
    "e_modelparameters = d1.entity('model_parameters', (\n",
    "    ('modelparameters:gpu_enable', 1),\n",
    "    ('modelparameters:modelParameters', str(model)),\n",
    "    ('modelparameters:neuron_number', neuron_number), \n",
    "    ('modelparameters:loss_function', 'nn.CrossEntropyLoss()'), \n",
    "    ('modelparameters:optimizer', 'torch.optim.Adam('), \n",
    "    ('modelparameters:optimizer_default_learning_rate', default), \n",
    "    ('modelparameters:optimizer_learning_rate', str(lr)), \n",
    "    ('modelparameters:activation_function', 'F.softmax(self.layer3(x), dim=1)'), \n",
    "))\n",
    "a_setmodelparameters = d1.activity('set_model_parameters()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_modelparameters, a_setmodelparameters, None, {'packages:fct': 'set'})\n",
    "d1.used(a_setmodelparameters, e_dataingestion)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91636abf",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training\n",
    "EPOCHS  = 100\n",
    "X_train = Variable(torch.from_numpy(X_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()\n",
    "X_test  = Variable(torch.from_numpy(X_test)).float()\n",
    "y_test  = Variable(torch.from_numpy(y_test)).long()\n",
    "\n",
    "loss_list     = np.zeros((EPOCHS,))\n",
    "accuracy_list = np.zeros((EPOCHS,))\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss_list[epoch] = loss.item()\n",
    "    \n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\n",
    "        accuracy_list[epoch] = correct.mean()\n",
    "\n",
    "#set_training\n",
    "d1.add_namespace('training', 'training.org')\n",
    "\n",
    "e_training = d1.entity('training', (\n",
    "    ('training:epochs', EPOCHS),\n",
    "    ('training:numberOfParameters', hierarchical_summary(model, print_summary = False)[1]),\n",
    "))\n",
    "a_settraining = d1.activity('set_training()', datetime.datetime.now())\n",
    "a_hierarchichalsummary = d1.activity('hierarchical_summary(model, print_summary = False)[1]')\n",
    "d1.wasGeneratedBy(e_training, a_settraining, None, {'packages:fct': 'set'})\n",
    "d1.wasInformedBy(a_settraining, a_hierarchichalsummary)\n",
    "d1.used(a_settraining, e_modelparameters)\n",
    "d1.used(a_settraining, e_datasegregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c4beb",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Accuracy and Loss from Training\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "\n",
    "ax1.plot(accuracy_list)\n",
    "ax1.set_ylabel(\"validation accuracy\")\n",
    "ax2.plot(loss_list)\n",
    "ax2.set_ylabel(\"validation loss\")\n",
    "ax2.set_xlabel(\"epochs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2779187",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix = confusion_matrix(y_test, torch.argmax(y_pred, dim=1))\n",
    "confusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85109352",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = f1_score(y_test, torch.argmax(y_pred, dim=1), average=None)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f3b86",
   "metadata": {},
   "source": [
    "### Mean Absolute Error & Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(y_test, torch.argmax(y_pred, dim=1), multioutput='uniform_average')\n",
    "MSE = mean_squared_error(y_test, torch.argmax(y_pred, dim=1), multioutput='uniform_average')\n",
    "print(MAE)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54b3e9",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a3182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# One hot encoding\n",
    "enc = OneHotEncoder()\n",
    "Y_onehot = enc.fit_transform(y_test[:, np.newaxis]).toarray()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).numpy()\n",
    "    fpr, tpr, threshold = roc_curve(Y_onehot.ravel(), y_pred.ravel())\n",
    "    \n",
    "plt.plot(fpr, tpr, label='AUC = {:.3f}'.format(auc(fpr, tpr)))\n",
    "AUC = '{:.5f}'.format(auc(fpr, tpr))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend();\n",
    "\n",
    "#set_evaluation\n",
    "d1.add_namespace('evaluation', 'evaluation.org')\n",
    "\n",
    "e_evaluation = d1.entity('evaluation', (\n",
    "    ('evaluation:Accuracy', accuracy_list[(len(accuracy_list)-1)]),\n",
    "    ('evaluation:Loss', loss_list[(len(loss_list)-1)]),\n",
    "    ('evaluation:Confusion Matrix', str(confusionMatrix)),\n",
    "    ('evaluation:AUC', float(AUC)),\n",
    "    ('evaluation:F1 Score', str(F1)),\n",
    "    ('evaluation:Mean Absolute Error', MAE),\n",
    "    ('evaluation:Mean Squared Error', MSE),\n",
    "))\n",
    "a_settraining = d1.activity('set_evaluation()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_evaluation, a_settraining, None, {'packages:fct': 'set'})\n",
    "d1.used(a_settraining, e_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab792f7a",
   "metadata": {},
   "source": [
    "### Generate Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2613f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add visualization to PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "#get time for filenames\n",
    "timestring = time.strftime('%Y%m%d-%H%M%S')\n",
    "timestring\n",
    "ProvenanceNameImage = ('Provenance_MulticlassClassification_' + timestring + '.png')\n",
    "\n",
    "dot = prov_to_dot(d1)\n",
    "dot.write_png('../GeneratedProvenanceData/'+ProvenanceNameImage)\n",
    "\n",
    "provenanceImage_open = widgets.Button(description = 'Open Image File')\n",
    "display(provenanceImage_open)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    provenanceImage_open.on_click = webbrowser.open('http://localhost:8888/lab/tree/extension/GeneratedProvenanceData/'+ProvenanceNameImage)\n",
    "\n",
    "provenanceImage_open.on_click(on_button_clicked)\n",
    "Image('../GeneratedProvenanceData/'+ProvenanceNameImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480a42a",
   "metadata": {},
   "source": [
    "### Write Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProvenanceName = ('Provenance_MulticlassClassification_' + timestring + '.json')\n",
    "\n",
    "with open('../GeneratedProvenanceData/'+ProvenanceName, 'w') as prov_file:\n",
    "    prov_file.write(d1.serialize(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ceb229",
   "metadata": {},
   "source": [
    "### Show Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def544e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "provenance_open = widgets.Button(description = 'Open Provenance Data File')\n",
    "display(provenance_open)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    #provenance_open.on_click = webbrowser.open('http://localhost:8888/lab/tree/GeneratedProvenanceData/'+ProvenanceName)\n",
    "\tprovenance_open.on_click = webbrowser.open('http://localhost:8888/lab/tree/extension/GeneratedProvenanceData/'+ProvenanceName)\n",
    "\n",
    "provenance_open.on_click(on_button_clicked)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
