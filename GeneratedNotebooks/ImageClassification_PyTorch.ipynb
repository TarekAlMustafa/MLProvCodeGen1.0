{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85e4436",
   "metadata": {},
   "source": [
    "\n",
    "# Image Classification\n",
    "\n",
    "Building a machine learning model to solve Image Classification using the PyTorch framework.<br>\n",
    "Image Classification is one of the basic pattern recognition exercises. <br>\n",
    "Using Image files as its input, a model trained for Image classification will split a set of images into a given number of classes. <br>\n",
    "<br>\n",
    "This Notebook has been generated automatically using the JupyterLab extension ***MLProvCodeGen***.\n",
    "<br>\n",
    "The original Source Code is from this application https://github.com/jrieke/traingenerator <br>\n",
    "Made by: https://www.jrieke.com/ Twitter: https://twitter.com/jrieke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63d476",
   "metadata": {},
   "source": [
    "### Installs\n",
    "Install required packages before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee679079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy===1.22.2 ipywidgets===7.6.5 torch===1.10.2 torchvision===0.11.3 pytorch-ignite===0.4.6 gputil===1.4.0 psutil===5.9.0 py-cpuinfo===8.0.0 --user\n",
    "#torch currently not supported with python 3.10, downgrading to python 3.9.7 possibly required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2c531",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7398f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision as torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import ignite as pytorch_ignite\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, ClassificationReport\n",
    "import GPUtil\n",
    "import psutil\n",
    "import cpuinfo\n",
    "import platform\n",
    "from datetime import date\n",
    "import time\n",
    "import json\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bc9e4",
   "metadata": {},
   "source": [
    "### Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5efea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Tarek Al Mustafa', 'email': 'tarek.almustafa@uni-jena.de', 'title': 'Image Classification', 'creation_date': '2022-03-25', 'task_type': 'ImageClassification_pytorch'}\n",
      "{'Python Version': '3.9.7.final.0 (64 bit)', 'CPU': 'AMD Ryzen 7 3700X 8-Core Processor', 'RAM': '15.95GB', 'Operating System': 'Windows 10 Version: 10.0.19041 Machine: AMD64', 'GPUs': \"[(0, 'NVIDIA GeForce GTX 1060 6GB')]\"}\n",
      "{'numpy': '1.22.2', 'ipywidgets': '7.6.5', 'torch': '1.10.2+cpu', 'torchvision': '0.11.3+cpu', 'pytorch-ignite': '0.4.6', 'gputil': '1.4.0', 'psutil': '5.9.0', 'py-cpuinfo': 'py-cpuinfo                    8.0.0'}\n"
     ]
    }
   ],
   "source": [
    "def get_size(bytes, suffix=\"B\"):\n",
    "    \"\"\"\n",
    "    Scale bytes to its proper format\n",
    "    e.g:\n",
    "        1253656 => '1.20MB'\n",
    "        1253656678 => '1.17GB'\n",
    "    \"\"\"\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
    "        bytes /= factor\n",
    "\n",
    "def set_experiment_info() :\n",
    "    created_by = \"Tarek Al Mustafa\"\n",
    "    email = \"tarek.almustafa@uni-jena.de\"\n",
    "    title = \"Image Classification\"\n",
    "    task_type = \"ImageClassification_pytorch\"\n",
    "    creation_date = str(date.today())\n",
    "    \n",
    "    experiment_info = { \n",
    "            'author': created_by,\n",
    "            'email': email,\n",
    "            'title': title,\n",
    "            'creation_date': creation_date,\n",
    "            'task_type': task_type}\n",
    "    \n",
    "    return experiment_info\n",
    "\n",
    "def set_hardware_info():\n",
    "    uname = platform.uname()\n",
    "    sysInfo = str(uname.system +' '+ uname.release +' Version: '+ uname.version +' Machine: '+ uname.machine)\n",
    "    \n",
    "    svmem = psutil.virtual_memory()\n",
    "\n",
    "    GPUs = GPUtil.getGPUs()\n",
    "    gpuList = []\n",
    "    for gpu in GPUs:\n",
    "        gpu_id = gpu.id\n",
    "        gpu_name = gpu.name\n",
    "        gpuList.append((gpu_id , gpu_name))\n",
    "\n",
    "    hardware_info = {\n",
    "        \"Python Version\": cpuinfo.get_cpu_info()['python_version'],\n",
    "        \"CPU\": cpuinfo.get_cpu_info()['brand_raw'],\n",
    "        \"RAM\": get_size(svmem.total),\n",
    "        \"Operating System\": sysInfo,\n",
    "        \"GPUs\": str(gpuList) }\n",
    "    \n",
    "    return hardware_info\n",
    "\n",
    "def set_packages():\n",
    "    cpuInfo_version = !pip list | grep -i py-cpuinfo\n",
    "    pytorch_model_summary_version = !pip list | grep -i pytorch-model-summary\n",
    "    packages = {\n",
    "        \"numpy\" : np.__version__,\n",
    "        \"ipywidgets\" : widgets.__version__,\n",
    "        \"torch\" : torch.__version__,\n",
    "        \"torchvision\" : torchvision.__version__,\n",
    "        \"pytorch-ignite\" : pytorch_ignite.__version__,\n",
    "        \"gputil\" : GPUtil.__version__, \n",
    "        \"psutil\" : psutil.__version__,\n",
    "        \"py-cpuinfo\" : cpuInfo_version[0]}\n",
    "\n",
    "    return packages\n",
    "\n",
    "print(set_experiment_info())\n",
    "print(set_hardware_info())\n",
    "print(set_packages())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d47ae",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66738fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = getattr(datasets, 'MNIST')\n",
    "\n",
    "def set_data_ingestion():\n",
    "    dataInfo = training_dataset.__len__\n",
    "    root_location =  str(dataInfo).splitlines()[2]\n",
    "    data_ingestion = {\n",
    "\t\t\"data_format\" : 'Public dataset',\n",
    "        \"dataset_id\" : 'MNIST',\n",
    "        \"feature_classes\" : 10,\n",
    "        \"training_samples\" : training_dataset.__len__(),\n",
    "        \"testing_samples\" : testing_dataset.__len__(),\n",
    "        \"root_location\" : root_location}\n",
    "    \n",
    "    return data_ingestion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f7219",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be242ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), \n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # grayscale to RGB\n",
    "])\n",
    "\n",
    "def set_data_preparation():\n",
    "    dataInfo = training_dataset.__len__\n",
    "    transform_method = str(dataInfo).splitlines()[4:11]\n",
    "    data_preparation = {\n",
    "        \"preprocessing\" : str(transform_method)}\n",
    "    \n",
    "    return data_preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb4ba1",
   "metadata": {},
   "source": [
    "### Data Segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05724d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device.\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 128\n",
    "print_every = 1  # batches\n",
    "# Wrap in data loader.\n",
    "training_dataset = dataset(\"./data\", train=True, download=True, transform=transform)\n",
    "#training_dataset = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "testing_dataset = dataset(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "if use_cuda:\n",
    "    kwargs = {\"pin_memory\": True, \"num_workers\": 1}\n",
    "else:\n",
    "    kwargs = {}\n",
    "\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "val_loader = None\n",
    "\n",
    "def set_data_segregation():\n",
    "    data_segregation = {\n",
    "        \"training_dataset\" : str(training_dataset.__len__),\n",
    "        \"testing_dataset\" : str(testing_dataset.__len__)}\n",
    "    \n",
    "    return data_segregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d650273",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6078f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up model, loss, optimizer.\n",
    "lr = 0.001\n",
    "model = models.resnet18(pretrained=0)\n",
    "model = model.to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def set_model_parameters():\n",
    "    model_parameters = {\n",
    "        \"model_name\" : 'resnet18',\n",
    "        \"pretrained\" : 0,\n",
    "        \"gpu_enable\" : 1,\n",
    "        \"modelParameters\" : str(model),\n",
    "        \"loss_function\" : 'CrossEntropyLoss',\n",
    "        \"optimizer\" : 'Adam',\n",
    "        \"optimizer_learning_rate\": lr,\n",
    "\t\t\"save_checkpoint\" : 0,\n",
    "\t\t\"num_classes\" : 1000}\n",
    "    return model_parameters\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9414c89",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da298c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1, batch 1 / 469: loss: 7.003\n",
      "Epoch 1 / 1, batch 2 / 469: loss: 5.469\n",
      "Epoch 1 / 1, batch 3 / 469: loss: 3.940\n",
      "Epoch 1 / 1, batch 4 / 469: loss: 2.956\n",
      "Epoch 1 / 1, batch 5 / 469: loss: 2.549\n",
      "Epoch 1 / 1, batch 6 / 469: loss: 1.780\n",
      "Epoch 1 / 1, batch 7 / 469: loss: 1.431\n",
      "Epoch 1 / 1, batch 8 / 469: loss: 1.222\n",
      "Epoch 1 / 1, batch 9 / 469: loss: 0.979\n",
      "Epoch 1 / 1, batch 10 / 469: loss: 0.899\n",
      "Epoch 1 / 1, batch 11 / 469: loss: 0.723\n",
      "Epoch 1 / 1, batch 12 / 469: loss: 0.643\n",
      "Epoch 1 / 1, batch 13 / 469: loss: 0.560\n",
      "Epoch 1 / 1, batch 14 / 469: loss: 0.644\n",
      "Epoch 1 / 1, batch 15 / 469: loss: 0.458\n",
      "Epoch 1 / 1, batch 16 / 469: loss: 0.500\n",
      "Epoch 1 / 1, batch 17 / 469: loss: 0.380\n",
      "Epoch 1 / 1, batch 18 / 469: loss: 0.322\n",
      "Epoch 1 / 1, batch 19 / 469: loss: 0.494\n",
      "Epoch 1 / 1, batch 20 / 469: loss: 0.353\n",
      "Epoch 1 / 1, batch 21 / 469: loss: 0.285\n",
      "Epoch 1 / 1, batch 22 / 469: loss: 0.275\n",
      "Epoch 1 / 1, batch 23 / 469: loss: 0.192\n",
      "Epoch 1 / 1, batch 24 / 469: loss: 0.185\n",
      "Epoch 1 / 1, batch 25 / 469: loss: 0.288\n",
      "Epoch 1 / 1, batch 26 / 469: loss: 0.169\n",
      "Epoch 1 / 1, batch 27 / 469: loss: 0.198\n",
      "Epoch 1 / 1, batch 28 / 469: loss: 0.149\n",
      "Epoch 1 / 1, batch 29 / 469: loss: 0.226\n",
      "Epoch 1 / 1, batch 30 / 469: loss: 0.207\n",
      "Epoch 1 / 1, batch 31 / 469: loss: 0.139\n",
      "Epoch 1 / 1, batch 32 / 469: loss: 0.393\n",
      "Epoch 1 / 1, batch 33 / 469: loss: 0.157\n",
      "Epoch 1 / 1, batch 34 / 469: loss: 0.222\n",
      "Epoch 1 / 1, batch 35 / 469: loss: 0.128\n",
      "Epoch 1 / 1, batch 36 / 469: loss: 0.183\n",
      "Epoch 1 / 1, batch 37 / 469: loss: 0.235\n",
      "Epoch 1 / 1, batch 38 / 469: loss: 0.127\n",
      "Epoch 1 / 1, batch 39 / 469: loss: 0.182\n",
      "Epoch 1 / 1, batch 40 / 469: loss: 0.157\n",
      "Epoch 1 / 1, batch 41 / 469: loss: 0.125\n",
      "Epoch 1 / 1, batch 42 / 469: loss: 0.193\n",
      "Epoch 1 / 1, batch 43 / 469: loss: 0.153\n",
      "Epoch 1 / 1, batch 44 / 469: loss: 0.092\n",
      "Epoch 1 / 1, batch 45 / 469: loss: 0.095\n",
      "Epoch 1 / 1, batch 46 / 469: loss: 0.121\n",
      "Epoch 1 / 1, batch 47 / 469: loss: 0.134\n",
      "Epoch 1 / 1, batch 48 / 469: loss: 0.266\n",
      "Epoch 1 / 1, batch 49 / 469: loss: 0.137\n",
      "Epoch 1 / 1, batch 50 / 469: loss: 0.188\n",
      "Epoch 1 / 1, batch 51 / 469: loss: 0.141\n",
      "Epoch 1 / 1, batch 52 / 469: loss: 0.118\n",
      "Epoch 1 / 1, batch 53 / 469: loss: 0.232\n",
      "Epoch 1 / 1, batch 54 / 469: loss: 0.137\n",
      "Epoch 1 / 1, batch 55 / 469: loss: 0.143\n",
      "Epoch 1 / 1, batch 56 / 469: loss: 0.098\n",
      "Epoch 1 / 1, batch 57 / 469: loss: 0.182\n",
      "Epoch 1 / 1, batch 58 / 469: loss: 0.189\n",
      "Epoch 1 / 1, batch 59 / 469: loss: 0.224\n",
      "Epoch 1 / 1, batch 60 / 469: loss: 0.139\n",
      "Epoch 1 / 1, batch 61 / 469: loss: 0.115\n",
      "Epoch 1 / 1, batch 62 / 469: loss: 0.144\n",
      "Epoch 1 / 1, batch 63 / 469: loss: 0.180\n",
      "Epoch 1 / 1, batch 64 / 469: loss: 0.128\n",
      "Epoch 1 / 1, batch 65 / 469: loss: 0.111\n",
      "Epoch 1 / 1, batch 66 / 469: loss: 0.123\n",
      "Epoch 1 / 1, batch 67 / 469: loss: 0.199\n",
      "Epoch 1 / 1, batch 68 / 469: loss: 0.104\n",
      "Epoch 1 / 1, batch 69 / 469: loss: 0.134\n",
      "Epoch 1 / 1, batch 70 / 469: loss: 0.121\n",
      "Epoch 1 / 1, batch 71 / 469: loss: 0.083\n",
      "Epoch 1 / 1, batch 72 / 469: loss: 0.181\n",
      "Epoch 1 / 1, batch 73 / 469: loss: 0.066\n",
      "Epoch 1 / 1, batch 74 / 469: loss: 0.146\n",
      "Epoch 1 / 1, batch 75 / 469: loss: 0.160\n",
      "Epoch 1 / 1, batch 76 / 469: loss: 0.102\n",
      "Epoch 1 / 1, batch 77 / 469: loss: 0.173\n",
      "Epoch 1 / 1, batch 78 / 469: loss: 0.126\n",
      "Epoch 1 / 1, batch 79 / 469: loss: 0.049\n",
      "Epoch 1 / 1, batch 80 / 469: loss: 0.151\n",
      "Epoch 1 / 1, batch 81 / 469: loss: 0.109\n",
      "Epoch 1 / 1, batch 82 / 469: loss: 0.112\n",
      "Epoch 1 / 1, batch 83 / 469: loss: 0.158\n",
      "Epoch 1 / 1, batch 84 / 469: loss: 0.073\n",
      "Epoch 1 / 1, batch 85 / 469: loss: 0.132\n",
      "Epoch 1 / 1, batch 86 / 469: loss: 0.084\n",
      "Epoch 1 / 1, batch 87 / 469: loss: 0.052\n",
      "Epoch 1 / 1, batch 88 / 469: loss: 0.263\n",
      "Epoch 1 / 1, batch 89 / 469: loss: 0.128\n"
     ]
    }
   ],
   "source": [
    "def set_train_log(log: str, value: str):\n",
    "    log+= value\n",
    "    return log\n",
    "\n",
    "num_epochs = 1\n",
    "epoch_log = \"\"\n",
    "# Set up pytorch-ignite trainer and evaluator.\n",
    "trainer = create_supervised_trainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_func,\n",
    "    device=device,\n",
    ")\n",
    "metrics = {\n",
    "\t\"report\": ClassificationReport(),\n",
    "    \"accuracy\": Accuracy(),\n",
    "    \"loss\": Loss(loss_func),\n",
    "}\n",
    "evaluator = create_supervised_evaluator(\n",
    "    model, metrics=metrics, device=device\n",
    ")\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=print_every))\n",
    "def log_batch(trainer):\n",
    "    batch = (trainer.state.iteration - 1) % trainer.state.epoch_length + 1\n",
    "    print(\n",
    "        f\"Epoch {trainer.state.epoch} / {num_epochs}, \"\n",
    "        f\"batch {batch} / {trainer.state.epoch_length}: \"\n",
    "        f\"loss: {trainer.state.output:.3f}\"\n",
    "    )\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_epoch(trainer):\n",
    "    print(f\"Epoch {trainer.state.epoch} / {num_epochs} average results: \")\n",
    "    train_log = set_train_log('', (f\"Epoch {trainer.state.epoch} / {num_epochs} average results: \"))\n",
    "\n",
    "    def log_results(name, metrics, epoch):\n",
    "        print(\n",
    "            f\"{name + ':':6} loss: {metrics['loss']:.3f}, \"\n",
    "            f\"accuracy: {metrics['accuracy']:.3f}\"\n",
    "        )\n",
    "        \n",
    "        log = set_train_log(train_log, (\n",
    "            f\"{name + ':':6} loss: {metrics['loss']:.3f}, \"\n",
    "            f\"accuracy: {metrics['accuracy']:.3f}\"\n",
    "        ))\n",
    "        return log\n",
    "\n",
    "    # Train data.\n",
    "    evaluator.run(train_loader)\n",
    "    log_results(\"train\", evaluator.state.metrics, trainer.state.epoch)\n",
    "    \n",
    "    # Val data.\n",
    "    if val_loader:\n",
    "        evaluator.run(val_loader)\n",
    "        log_results(\"val\", evaluator.state.metrics, trainer.state.epoch)\n",
    "\n",
    "    # Test data.\n",
    "    if test_loader:\n",
    "        evaluator.run(test_loader)\n",
    "        log_results(\"test\", evaluator.state.metrics, trainer.state.epoch)\n",
    "\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "    return train_log\n",
    "\n",
    "# Start training.\n",
    "train_log = trainer.run(train_loader, max_epochs=num_epochs)\n",
    "\n",
    "print(train_log)\n",
    "\n",
    "def set_training():\n",
    "\n",
    "    training = {\n",
    "\t\"batch_size\" : batch_size,\n",
    "    \"epochs\" : num_epochs,\n",
    "    \"train_metrics\" : str(train_log),\n",
    "\t\"print_progress\" : 1}\n",
    "    \n",
    "    return training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21fd4de",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e01ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_evaluation():\n",
    "    evaluation = {\n",
    "\t\t\"report\" : evaluator.state.metrics['report'],\n",
    "        \"accuracy\" : evaluator.state.metrics['accuracy'],\n",
    "        \"loss\" : evaluator.state.metrics['loss']\n",
    "    }\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef74ddc",
   "metadata": {},
   "source": [
    "### Generate Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e29296",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_experiment_info()\n",
    "set_hardware_info()\n",
    "set_packages()\n",
    "set_data_ingestion()\n",
    "set_data_preparation()\n",
    "set_data_segregation()\n",
    "set_model_parameters()\n",
    "set_training()\n",
    "set_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabf7a5",
   "metadata": {},
   "source": [
    "### Write Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1123a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestring = time.strftime('%Y%m%d-%H%M%S')\n",
    "timestring\n",
    "ProvenanceName = ('Provenance_ImageClassification_PyTorch_' + timestring + '.json')\n",
    "\n",
    "with open('../GeneratedProvenanceData/'+ProvenanceName, 'w') as prov_file:\n",
    "    prov_file.write('{' + '\\n  ')\n",
    "    prov_file.write('\"experiment_info\":' + json.dumps(set_experiment_info(),sort_keys=False, indent=4) +',' + '\\n\\n' )\n",
    "    prov_file.write('\"hardware_info\":' + json.dumps(set_hardware_info(),sort_keys=False, indent=4) +',' + '\\n\\n' )\n",
    "    prov_file.write('\"packages\":' + json.dumps(set_packages(),sort_keys=False, indent=4) +',' + '\\n\\n' )\n",
    "    prov_file.write('\"data_ingestion\":' + json.dumps(set_data_ingestion(),sort_keys=False, indent=4) +',' + '\\n\\n' )\n",
    "    prov_file.write('\"data_preparation\":' + json.dumps(set_data_preparation(),sort_keys=False, indent=4) +',' + '\\n\\n' )\n",
    "    prov_file.write('\"data_segregation\":' + json.dumps(set_data_segregation(),sort_keys=False, indent=4) +',' + '\\n\\n' )\n",
    "    prov_file.write('\"model_parameters\":' + json.dumps(set_model_parameters(),sort_keys=False, indent=4) +',' + '\\n\\n' )\n",
    "    prov_file.write('\"training\":' + json.dumps(set_training(),sort_keys=False, indent=4) +',' + '\\n\\n' )\n",
    "    prov_file.write('\"evaluation\":' + json.dumps(set_evaluation(),sort_keys=False, indent=4) + '\\n' )\n",
    "    prov_file.write('}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c5c0c",
   "metadata": {},
   "source": [
    "### Open Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "provenance_open = widgets.Button(description = 'Open Provenance Data File')\n",
    "display(provenance_open)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    provenance_open.on_click = webbrowser.open('http://localhost:8888/lab/tree/GeneratedProvenanceData/'+ProvenanceName)\n",
    "\n",
    "provenance_open.on_click(on_button_clicked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
