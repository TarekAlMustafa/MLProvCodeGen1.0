{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899fa76e",
   "metadata": {},
   "source": [
    "\n",
    "# Image Classification\n",
    "\n",
    "Building a machine learning model to solve Image Classification using the PyTorch framework.<br>\n",
    "Image Classification is one of the basic pattern recognition exercises. <br>\n",
    "Using Image files as its input, a model trained for Image classification will split a set of images into a given number of classes. <br>\n",
    "<br>\n",
    "This Notebook has been generated automatically using the JupyterLab extension ***MLProvCodeGen***.\n",
    "<br>\n",
    "The original Source Code is from this application https://github.com/jrieke/traingenerator <br>\n",
    "Made by: https://www.jrieke.com/ Twitter: https://twitter.com/jrieke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c7b30",
   "metadata": {},
   "source": [
    "### Installs\n",
    "Install required packages before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0357ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy===1.22.2 ipywidgets===7.6.5 torch===1.10.2 torchvision===0.11.3 pytorch-ignite===0.4.6 pytorch-lightning===1.5.10 gputil===1.4.0 psutil===5.9.0 py-cpuinfo===8.0.0 prov===2.0.0 pydot===1.4.2 --user\n",
    "#torch currently not supported with python 3.10, downgrading to python 3.9.7 possibly required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a94811",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1430a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision as torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import ignite as pytorch_ignite\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, ClassificationReport\n",
    "import GPUtil\n",
    "import psutil\n",
    "import cpuinfo\n",
    "import platform\n",
    "import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import json\n",
    "import webbrowser\n",
    "import IPython\n",
    "from IPython.display import display, Image\n",
    "import prov\n",
    "from prov.model import ProvDocument\n",
    "from prov.dot import prov_to_dot\n",
    "import os\n",
    "import pytorch_lightning\n",
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b0caa",
   "metadata": {},
   "source": [
    "### Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78230e36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pytorch_lightning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13836/1114174230.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m'packages:torchvision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m'packages:pytorch-ignite'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpytorch_ignite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[1;34m'packages:pytorch-lightning'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpytorch_lightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'packages:gputil'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGPUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'packages:psutil'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pytorch_lightning' is not defined"
     ]
    }
   ],
   "source": [
    "def get_size(bytes, suffix=\"B\"):\n",
    "    \"\"\"\n",
    "    Scale bytes to its proper format\n",
    "    e.g:\n",
    "        1253656 => '1.20MB'\n",
    "        1253656678 => '1.17GB'\n",
    "    \"\"\"\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
    "        bytes /= factor\n",
    "\n",
    "d1 = ProvDocument()\n",
    "d1.set_default_namespace('provenanceexample.org')\n",
    "#set_experiment_info()\n",
    "d1.add_namespace('experimentinfo', 'experimentinfo.org')\n",
    "e_experimentinfo = d1.entity('experiment_info', (\n",
    "    ('experimentinfo:author', 'Tarek Al Mustafa'),\n",
    "    ('experimentinfo:email', 'tarek.almustafa@uni-jena.de'),\n",
    "    ('experimentinfo:title', 'Image Classification'),\n",
    "    ('experimentinfo:creation_date', str(date.today())),\n",
    "    ('experimentinfo:task_type', 'ImageClassification_pytorch'),\n",
    "))\n",
    "\n",
    "a_setexperimentinfo = d1.activity('set_experiment_info()', datetime.datetime.now(), None)\n",
    "a_setdate = d1.activity('date.today()')\n",
    "\n",
    "d1.wasGeneratedBy(e_experimentinfo, a_setexperimentinfo, None, {'ex:fct': 'set'})\n",
    "d1.wasAssociatedWith('experiment_info', 'Tarek Al Mustafa', None, None)\n",
    "d1.agent('Tarek Al Mustafa') \n",
    "d1.wasInformedBy(a_setexperimentinfo, a_setdate)   \n",
    "\n",
    "\n",
    "#set_hardware_info()\n",
    "uname = platform.uname()\n",
    "sysInfo = str(uname.system +' '+ uname.release +' Version: '+ uname.version +' Machine: '+ uname.machine)\n",
    "    \n",
    "svmem = psutil.virtual_memory()\n",
    "\n",
    "GPUs = GPUtil.getGPUs()\n",
    "gpuList = []\n",
    "for gpu in GPUs:\n",
    "    gpu_id = gpu.id\n",
    "    gpu_name = gpu.name\n",
    "    gpuList.append((gpu_id , gpu_name))\n",
    "\n",
    "        \n",
    "d1.add_namespace('hardwareinfo', 'hardwareinfo.org')\n",
    "e_hardwareinfo = d1.entity('hardware_info', (\n",
    "    ('hardwareinfo:Python Version', cpuinfo.get_cpu_info()['python_version']),\n",
    "    ('hardwareinfo:CPU', cpuinfo.get_cpu_info()['brand_raw']),\n",
    "    ('hardwareinfo:RAM',  get_size(svmem.total)),\n",
    "    ('hardwareinfo:Operating System', sysInfo),\n",
    "    ('hardwareinfo:GPUs', str(gpuList)),\n",
    "))\n",
    "#activity\n",
    "a_sethardwareinfo = d1.activity('set_hardware_info()', datetime.datetime.now(), None)\n",
    "a_platform_uname = d1.activity('platform.uname()')\n",
    "a_cpuinfo = d1.activity('cpuinfo.get_cpu_info()')\n",
    "a_svmemtotal = d1.activity('svmem.total')\n",
    "a_getsize = d1.activity('get_size(svmem.total)')\n",
    "a_GPUtilgetGPU = d1.activity('GPUtil.getGPUs()')\n",
    "d1.wasGeneratedBy(e_hardwareinfo, a_sethardwareinfo, None, {'experimentinfo:fct': 'set'})\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_platform_uname)\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_cpuinfo)\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_svmemtotal)\n",
    "d1.wasInformedBy(a_svmemtotal, a_getsize)\n",
    "d1.wasInformedBy(a_sethardwareinfo, a_GPUtilgetGPU)\n",
    "\n",
    "\n",
    "#set_packages\n",
    "cpuInfo_version = !pip list | grep -i py-cpuinfo\n",
    "pytorch_model_summary_version = !pip list | grep -i pytorch-model-summary\n",
    "\n",
    "d1.add_namespace('packages', 'packages.org')\n",
    "\n",
    "e_packages = d1.entity('packages', (\n",
    "    ('packages:numpy', np.__version__),\n",
    "\t('packages:ipywidgets', widgets.__version__),\n",
    "\t('packages:torch', torch.__version__),\n",
    "\t('packages:torchvision', torchvision.__version__),\n",
    "\t('packages:pytorch-ignite', pytorch_ignite.__version__),\n",
    "\t('packages:pytorch-lightning',pytorch_lightning.__version__),\n",
    "    ('packages:gputil', GPUtil.__version__),\n",
    "    ('packages:psutil', psutil.__version__),\n",
    "    ('packages:py-cpuinfo', cpuInfo_version[0]),\n",
    "    ('packages:prov', prov.__version__),  \n",
    "))\n",
    "a_setpackages = d1.activity('set_packages()', datetime.datetime.now())\n",
    "a_getVersion = d1.activity('{package_name}.__version__')\n",
    "a_getVersion_py_cpuinfo = d1.activity('!pip list | grep -i py-cpuinfo')\n",
    "d1.wasGeneratedBy(e_packages, a_setpackages, None, {'packages:fct': 'set'})\n",
    "d1.wasInformedBy(a_setpackages,a_getVersion)\n",
    "d1.wasInformedBy(a_setpackages,a_getVersion_py_cpuinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b110e0",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ca9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = getattr(datasets, 'MNIST')\n",
    "training_dataset = dataset(\"./data\", train=True, download=True)\n",
    "testing_dataset = dataset(\"./data\", train=False, download=True)\n",
    "\n",
    "#set_data_ingestion\n",
    "d1.add_namespace('dataingestion', 'dataingestion.org')\n",
    "\n",
    "dataInfo = training_dataset.__len__\n",
    "root_location =  str(dataInfo).splitlines()[2]\n",
    "\n",
    "e_dataingestion = d1.entity('data_ingestion', (\n",
    "    ('dataingestion:data_format', 'Public dataset'),\n",
    "    ('dataingestion:dataset_id', 'MNIST'),\n",
    "    ('dataingestion:feature_classes', 10),\n",
    "    ('dataingestion:training_samples',  training_dataset.__len__()),\n",
    "    ('dataingestion:testing_samples', testing_dataset.__len__()),\n",
    "    ('dataingestion:root_location', root_location),\n",
    "))\n",
    "a_setdataingestion = d1.activity('set_data_ingestion()', datetime.datetime.now())\n",
    "a_splitlines = ('str(dataInfo).splitlines()[2]')\n",
    "a_getlength = d1.activity('{dataset}.__len__()')\n",
    "d1.wasGeneratedBy(e_dataingestion, a_setdataingestion, None, {'packages:fct': 'set'})\n",
    "d1.wasInformedBy(a_setdataingestion, a_getlength)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460eee4",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84724f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), \n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # grayscale to RGB\n",
    "])\n",
    "\n",
    "#set_data_preparation\n",
    "d1.add_namespace('datapreparation', 'datapreparation.org')\n",
    "\n",
    "dataInfo = training_dataset.__len__\n",
    "transform_method = str(dataInfo).splitlines()[4:11]\n",
    "\n",
    "e_datapreparation = d1.entity('data_preparation', (\n",
    "        ('datapreparation:preprocessing', str(transform_method)),\n",
    "))\n",
    "a_setdatapreparation = d1.activity('set_data_preparation()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_datapreparation, a_setdatapreparation, None, {'packages:fct': 'set'})\n",
    "d1.used(a_setdatapreparation, e_dataingestion)\n",
    "d1.wasInformedBy(a_splitlines, a_getlength)\n",
    "d1.wasInformedBy(a_setdatapreparation, a_splitlines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9ecb6",
   "metadata": {},
   "source": [
    "### Data Segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device.\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 128\n",
    "print_every = 1  # batches\n",
    "# Wrap in data loader.\n",
    "training_dataset = dataset(\"./data\", train=True, download=True, transform=transform)\n",
    "testing_dataset = dataset(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "if use_cuda:\n",
    "    kwargs = {\"pin_memory\": True, \"num_workers\": 1}\n",
    "else:\n",
    "    kwargs = {}\n",
    "\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "val_loader = None\n",
    "\n",
    "#set_data_segregation\n",
    "d1.add_namespace('datasegregation', 'datasegregation.org')\n",
    "\n",
    "e_datasegregation = d1.entity('data_segregation', (\n",
    "    ('datasegregation:training_dataset', str(training_dataset.__len__)),\n",
    "    ('datasegregation:testing_dataset', str(testing_dataset.__len__)),\n",
    "))\n",
    "a_setdatasegregation = d1.activity('set_data_segregation()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_datasegregation, a_setdatasegregation, None, {'packages:fct': 'set'})\n",
    "d1.used(a_setdatasegregation, e_datapreparation)\n",
    "d1.wasInformedBy(a_setdatasegregation, a_getlength)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a6b79",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebdbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model, loss, optimizer.\n",
    "lr = 0.001\n",
    "model = models.resnet18(pretrained=0)\n",
    "num_classes = 1000\n",
    "model.fc = torch.nn.Linear(in_features=model.fc.in_features, out_features=num_classes, bias=True)\n",
    "model = model.to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#set_model_parameters\n",
    "d1.add_namespace('modelparameters', 'modelparameters.org')\n",
    "\n",
    "e_modelparameters = d1.entity('model_parameters', (\n",
    "    ('modelparameters:model_name', 'resnet18'),\n",
    "    ('modelparameters:save_checkpoint', 0),\n",
    "    ('modelparameters:pretrained', 0),\n",
    "    ('modelparameters:gpu_enable', 1),\n",
    "    #('modelparameters:modelParameters', str(model)),\n",
    "    ('modelparameters:loss_function', 'CrossEntropyLoss'),\n",
    "    ('modelparameters:optimizer', 'Adam'),\n",
    "    ('modelparameters:optimizer_learning_rate', lr),\n",
    "    ('modelparameters:num_classes', 1000),\n",
    "))\n",
    "a_setmodelparameters = d1.activity('set_model_parameters()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_modelparameters, a_setmodelparameters, None, {'packages:fct': 'set'})\n",
    "d1.used(a_setmodelparameters, e_dataingestion)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d4fbd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(2, workers=True)\n",
    "def set_train_log(log: str, value: str):\n",
    "    log+= value\n",
    "    return log\n",
    "\n",
    "num_epochs = 3\n",
    "epoch_log = \"\"\n",
    "# Set up pytorch-ignite trainer and evaluator.\n",
    "trainer = create_supervised_trainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_func,\n",
    "    device=device,\n",
    "\tdeterministic=True\n",
    ")\n",
    "metrics = {\n",
    "\t\"report\": ClassificationReport(),\n",
    "    \"accuracy\": Accuracy(),\n",
    "    \"loss\": Loss(loss_func),\n",
    "}\n",
    "evaluator = create_supervised_evaluator(\n",
    "    model, metrics=metrics, device=device\n",
    ")\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=print_every))\n",
    "def log_batch(trainer):\n",
    "    batch = (trainer.state.iteration - 1) % trainer.state.epoch_length + 1\n",
    "    print(\n",
    "        f\"Epoch {trainer.state.epoch} / {num_epochs}, \"\n",
    "        f\"batch {batch} / {trainer.state.epoch_length}: \"\n",
    "        f\"loss: {trainer.state.output:.3f}\"\n",
    "    )\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_epoch(trainer):\n",
    "    print(f\"Epoch {trainer.state.epoch} / {num_epochs} average results: \")\n",
    "    train_log = set_train_log('', (f\"Epoch {trainer.state.epoch} / {num_epochs} average results: \"))\n",
    "\n",
    "    def log_results(name, metrics, epoch):\n",
    "        print(\n",
    "            f\"{name + ':':6} loss: {metrics['loss']:.3f}, \"\n",
    "            f\"accuracy: {metrics['accuracy']:.3f}\"\n",
    "        )\n",
    "        \n",
    "        log = set_train_log(train_log, (\n",
    "            f\"{name + ':':6} loss: {metrics['loss']:.3f}, \"\n",
    "            f\"accuracy: {metrics['accuracy']:.3f}\"\n",
    "        ))\n",
    "        return log\n",
    "\n",
    "    # Train data.\n",
    "    evaluator.run(train_loader)\n",
    "    log_results(\"train\", evaluator.state.metrics, trainer.state.epoch)\n",
    "    \n",
    "    # Val data.\n",
    "    if val_loader:\n",
    "        evaluator.run(val_loader)\n",
    "        log_results(\"val\", evaluator.state.metrics, trainer.state.epoch)\n",
    "\n",
    "    # Test data.\n",
    "    if test_loader:\n",
    "        evaluator.run(test_loader)\n",
    "        log_results(\"test\", evaluator.state.metrics, trainer.state.epoch)\n",
    "\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "    return train_log\n",
    "\n",
    "# Start training.\n",
    "train_log = trainer.run(train_loader, max_epochs=num_epochs)\n",
    "\n",
    "print(train_log)\n",
    "\n",
    "#set_training\n",
    "d1.add_namespace('training', 'training.org')\n",
    "\n",
    "e_training = d1.entity('training', (\n",
    "    ('training:batch_size', batch_size),    \n",
    "\t('training:epochs', num_epochs),\n",
    "    ('training:train_metrics', str(train_log)),\n",
    "    ('training:print_progress', 1),\n",
    "\t('training:seed', 2),\n",
    "))\n",
    "a_settraining = d1.activity('set_training()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_training, a_settraining, None, {'packages:fct': 'set'})\n",
    "d1.used(a_settraining, e_modelparameters)\n",
    "d1.used(a_settraining, e_datasegregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d83ab2",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa529deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_evaluation\n",
    "d1.add_namespace('evaluation', 'evaluation.org')\n",
    "\n",
    "e_evaluation = d1.entity('evaluation', (\n",
    "    ('evaluation:accuracy', evaluator.state.metrics['accuracy']),\n",
    "    ('evaluation:loss', evaluator.state.metrics['loss']),\n",
    "))\n",
    "a_settraining = d1.activity('set_evaluation()', datetime.datetime.now())\n",
    "d1.wasGeneratedBy(e_evaluation, a_settraining, None, {'packages:fct': 'set'})\n",
    "d1.used(a_settraining, e_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4f7fe5",
   "metadata": {},
   "source": [
    "### Generate Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add visualization to PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "#get time for filenames\n",
    "timestring = time.strftime('%Y%m%d-%H%M%S')\n",
    "timestring\n",
    "ProvenanceNameImage = ('Provenance_ImageClassification_' + timestring + '.png')\n",
    "\n",
    "dot = prov_to_dot(d1)\n",
    "dot.write_png('../GeneratedProvenanceData/'+ProvenanceNameImage)\n",
    "\n",
    "provenanceImage_open = widgets.Button(description = 'Open Image File')\n",
    "display(provenanceImage_open)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    provenanceImage_open.on_click = webbrowser.open('http://localhost:8888/lab/tree/extension/GeneratedProvenanceData/'+ProvenanceNameImage)\n",
    "\n",
    "provenanceImage_open.on_click(on_button_clicked)\n",
    "Image('../GeneratedProvenanceData/'+ProvenanceNameImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf3fd6",
   "metadata": {},
   "source": [
    "### Write Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProvenanceName = ('Provenance_ImageClassification_' + timestring + '.json')\n",
    "\n",
    "with open('../GeneratedProvenanceData/'+ProvenanceName, 'w') as prov_file:\n",
    "    prov_file.write(d1.serialize(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c6ffed",
   "metadata": {},
   "source": [
    "### Open Provenance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51adbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "provenance_open = widgets.Button(description = 'Open Provenance Data File')\n",
    "display(provenance_open)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    #provenance_open.on_click = webbrowser.open('http://localhost:8888/lab/tree/GeneratedProvenanceData/'+ProvenanceName)\n",
    "\tprovenance_open.on_click = webbrowser.open('http://localhost:8888/lab/tree/extension/GeneratedProvenanceData/'+ProvenanceName)\n",
    "\n",
    "provenance_open.on_click(on_button_clicked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
