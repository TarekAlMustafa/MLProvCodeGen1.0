#Use GPU?
{% if use_gpu %}
use_cuda = torch.cuda.is_available()
{% else %}
use_cuda = False
{% endif %}
device = torch.device("cuda" if use_cuda else "cpu")

neuron_number = {{ neuron_number }}

#Configure Neural Network Models
class Model(nn.Module):
    def __init__(self, input_dim):
        super(Model, self).__init__()
        self.layer1 = nn.Linear(input_dim, {{ neuron_number }})
        self.layer2 = nn.Linear({{ neuron_number }}, {{ neuron_number }})
        self.layer3 = nn.Linear({{ neuron_number }}, output_dim)
        
    def forward(self, x):
        x = F.relu(self.layer1(x))
        x = F.relu(self.layer2(x))
        x = {{ activation_func }}
        return x

model     = Model(X_train.shape[1])
{% if default and optimizer == "torch.optim.SGD(" %}
optimizer = {{ optimizer}}model.parameters(), lr = 1)
{% elif default %}
optimizer = {{ optimizer }}model.parameters())
{% else %}
lr={{ lr }} 
if lr = 0:
	optimizer = {{ optimizer }}model.parameters())
else: 
	optimizer = {{ optimizer }}model.parameters(), lr=lr)
{% endif %}
loss_fn   = {{ loss_func }}

try:
    lr
except NameError:
    default = 1
    lr = None 
else:
    default = 0

#set_model_parameters
d1.add_namespace('modelparameters', 'modelparameters.org')

e_modelparameters = d1.entity('model_parameters', (
    ('modelparameters:gpu_enable', 1),
    ('modelparameters:modelParameters', str(model)),
    ('modelparameters:neuron_number', neuron_number), 
    ('modelparameters:loss_function', '{{ loss_func }}'), 
    ('modelparameters:optimizer', '{{ optimizer }}'), 
    ('modelparameters:optimizer_default_learning_rate', default), 
    ('modelparameters:optimizer_learning_rate', str(lr)), 
    ('modelparameters:activation_function', '{{ activation_func }}'), 
))
a_setmodelparameters = d1.activity('set_model_parameters()', datetime.datetime.now())
d1.wasGeneratedBy(e_modelparameters, a_setmodelparameters, None, {'packages:fct': 'set'})
d1.used(a_setmodelparameters, e_dataingestion)

model