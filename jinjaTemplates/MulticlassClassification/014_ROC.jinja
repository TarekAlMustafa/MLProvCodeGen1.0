#ROC Curve 
plt.figure(figsize=(10, 10))
plt.plot([0, 1], [0, 1], 'k--')

# One hot encoding
enc = OneHotEncoder()
Y_onehot = enc.fit_transform(y_test[:, np.newaxis]).toarray()

with torch.no_grad():
    y_pred = model(X_test).numpy()
    fpr, tpr, threshold = roc_curve(Y_onehot.ravel(), y_pred.ravel())
    
plt.plot(fpr, tpr, label='AUC = {:.3f}'.format(auc(fpr, tpr)))
AUC = '{:.5f}'.format(auc(fpr, tpr))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend();

#set_evaluation
d1.add_namespace('evaluation', 'evaluation.org')

e_evaluation = d1.entity('evaluation', (
    ('evaluation:Accuracy', accuracy_list[(len(accuracy_list)-1)]),
    ('evaluation:Loss', loss_list[(len(loss_list)-1)]),
    ('evaluation:Confusion Matrix', str(confusionMatrix)),
    ('evaluation:AUC', float(AUC)),
    ('evaluation:F1 Score', str(F1)),
    ('evaluation:Mean Absolute Error', MAE),
    ('evaluation:Mean Squared Error', MSE),
))
a_settraining = d1.activity('set_evaluation()', datetime.datetime.now())
d1.wasGeneratedBy(e_evaluation, a_settraining, None, {'packages:fct': 'set'})
d1.used(a_settraining, e_training)