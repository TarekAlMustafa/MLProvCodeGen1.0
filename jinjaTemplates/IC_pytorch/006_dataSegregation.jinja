# Set up device.
{% if gpu %}
use_cuda = torch.cuda.is_available()
{% else %}
use_cuda = False
{% endif %}
device = torch.device("cuda" if use_cuda else "cpu")
{% if data_format == "Public dataset" %}
batch_size = {{ batch_size }}
print_every = {{ print_every }}  # batches
# Wrap in data loader.
training_dataset = dataset("./data", train=True, download=True, transform=transform)
testing_dataset = dataset("./data", train=False, download=True, transform=transform)

if use_cuda:
    kwargs = {"pin_memory": True, "num_workers": 1}
else:
    kwargs = {}

train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, **kwargs)
test_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False, **kwargs)
val_loader = None

#set_data_segregation
d1.add_namespace('datasegregation', 'datasegregation.org')

e_datasegregation = d1.entity('data_segregation', (
    ('datasegregation:training_dataset', str(training_dataset.__len__)),
    ('datasegregation:testing_dataset', str(testing_dataset.__len__)),
))
a_setdatasegregation = d1.activity('set_data_segregation()', datetime.datetime.now())
d1.wasGeneratedBy(e_datasegregation, a_setdatasegregation, None, {'packages:fct': 'set'})
d1.used(a_setdatasegregation, e_datapreparation)
d1.wasInformedBy(a_setdatasegregation, a_getlength)
{% else %}
### Preprocessing
def preprocess(data, name):
    if data is None:  # val/test can be empty
        return None

    {% if data_format == "Image files" %}
    # Read image files to pytorch dataset.
    transform = transforms.Compose([
        transforms.Resize(256), 
        transforms.CenterCrop(224), 
        transforms.ToTensor(), 
        {# TODO: Maybe add normalization option even if model is not pretrained #}
        {% if pretrained %}
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        {% endif %}
    ])
    dataset = datasets.ImageFolder(data, transform=transform)
    {% elif data_format == "Numpy arrays" %}
    images, labels = data

    # Rescale images to 0-255 and convert to uint8.
    # Note: This is done for each dataset individually, which is usually ok if all 
    # datasets look similar. If not, scale all datasets based on min/ptp of train set.
    images = (images - np.min(images)) / np.ptp(images) * 255
    images = images.astype(np.uint8)

    # If images are grayscale, convert to RGB by duplicating channels.
    if images.shape[1] == 1:
        images = np.stack((images[:, 0],) * 3, axis=1)

    # Resize images and transform images torch tensor.
    images = images.transpose((0, 2, 3, 1))  # channels-last, required for transforms.ToPILImage
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize(256), 
        transforms.CenterCrop(224), 
        transforms.ToTensor(), 
        {% if pretrained %}
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        {% endif %}
    ])
    {# TODO: This is quite ugly and very inefficient #}
    images = torch.stack(list(map(transform, images)))

    # Convert labels to tensors.
    labels = torch.from_numpy(labels).long()

    # Construct dataset.
    dataset = TensorDataset(images, labels)
    {% endif %}

    # Wrap in data loader.
    {% if gpu %}
    if use_cuda:
        kwargs = {"pin_memory": True, "num_workers": 1}
    else:
        kwargs = {}
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=(name=="train"), **kwargs)
    {% else %}
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=(name=="train"))
    {% endif %}
    return loader

train_loader = preprocess(train_data, "train")
val_loader = preprocess(val_data, "val")
test_loader = preprocess(test_data, "test")
{% endif %}